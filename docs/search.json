[{"path":"index.html","id":"машинне-навчання","chapter":"Машинне навчання","heading":"Машинне навчання","text":"Ігор Мірошниченко2022-05-10","code":""},{"path":"index.html","id":"передмова","chapter":"Машинне навчання","heading":"Передмова","text":"Наразі підручник в процесі розробки.Якщо ви помітили неточності або помилки, будь-ласка напишіть мені: ihor.miroshnychenko@kneu.ua","code":""},{"path":"tidymodels.html","id":"tidymodels","chapter":" 1 Tidymodels","heading":" 1 Tidymodels","text":"Tidymodels - фреймворк для побудови моделей машинного навчання за допомогою мови програмування R.Розглянемо датасет з пінгвінами, який прийшов на заміну класичному датасету про іриси.Він добре підходить як під задачі регресії, так і під задачі класифікації.","code":"\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\npenguins\n## # A tibble: 344 x 8\n##    body_mass_g species island    bill_length_mm bill_depth_mm flipper_length_mm\n##          <int> <fct>   <fct>              <dbl>         <dbl>             <int>\n##  1        3750 Adelie  Torgersen           39.1          18.7               181\n##  2        3800 Adelie  Torgersen           39.5          17.4               186\n##  3        3250 Adelie  Torgersen           40.3          18                 195\n##  4          NA Adelie  Torgersen           NA            NA                  NA\n##  5        3450 Adelie  Torgersen           36.7          19.3               193\n##  6        3650 Adelie  Torgersen           39.3          20.6               190\n##  7        3625 Adelie  Torgersen           38.9          17.8               181\n##  8        4675 Adelie  Torgersen           39.2          19.6               195\n##  9        3475 Adelie  Torgersen           34.1          18.1               193\n## 10        4250 Adelie  Torgersen           42            20.2               190\n## # ... with 334 more rows, and 2 more variables: sex <fct>, year <int>\n\nglimpse(penguins)\n## Rows: 344\n## Columns: 8\n## $ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475,~\n## $ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade~\n## $ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgers~\n## $ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1,~\n## $ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1,~\n## $ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 18~\n## $ sex               <fct> male, female, female, NA, female, male, female, mal~\n## $ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 200~\n\npenguins <- penguins %>% \n  relocate(body_mass_g)"},{"path":"tidymodels.html","id":"розбиття-вибірки-на-тестову-та-навчальну.","chapter":" 1 Tidymodels","heading":"1.1 Розбиття вибірки на тестову та навчальну.","text":"Звичайне розбиття","code":"\nset.seed(2022)\npenguins_split <- initial_split(penguins, prop = .8)\n\npenguins_split\n## <Analysis/Assess/Total>\n## <275/69/344>\n\npenguins_train <- training(penguins_split)\n\npenguins_test  <-  testing(penguins_split)\n\ndim(penguins_train)\n## [1] 275   8\nset.seed(2022)\n\npenguins_split <- initial_split(penguins, prop = .8, strata = sex)\n\npenguins_split\n## <Analysis/Assess/Total>\n## <275/69/344>\n\npenguins_train <- training(penguins_split)\n\npenguins_test  <-  testing(penguins_split)\n\ndim(penguins_train)\n## [1] 275   8\n\npenguins_train %>% \n  count(sex)\n## # A tibble: 3 x 2\n##   sex        n\n##   <fct>  <int>\n## 1 female   131\n## 2 male     135\n## 3 <NA>       9\n\npenguins_test %>% \n  count(sex)\n## # A tibble: 3 x 2\n##   sex        n\n##   <fct>  <int>\n## 1 female    34\n## 2 male      33\n## 3 <NA>       2"},{"path":"tidymodels.html","id":"побудова-моделей-за-допомогою-tidymodels","chapter":" 1 Tidymodels","heading":"1.2 Побудова моделей за допомогою Tidymodels","text":"","code":"\nlinear_reg() %>% \n  set_engine(\"lm\") %>% \n  translate()\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm \n## \n## Model fit template:\n## stats::lm(formula = missing_arg(), data = missing_arg(), weights = missing_arg())\n\nlinear_reg(penalty = 1) %>% \n  set_engine(\"glmnet\") %>% \n  translate()\n## Linear Regression Model Specification (regression)\n## \n## Main Arguments:\n##   penalty = 1\n## \n## Computational engine: glmnet \n## \n## Model fit template:\n## glmnet::glmnet(x = missing_arg(), y = missing_arg(), weights = missing_arg(), \n##     family = \"gaussian\")\n\nlinear_reg() %>% \n  set_engine(\"stan\") %>% \n  translate()\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: stan \n## \n## Model fit template:\n## rstanarm::stan_glm(formula = missing_arg(), data = missing_arg(), \n##     weights = missing_arg(), family = stats::gaussian, refresh = 0)\nlm_model <- \n  linear_reg() %>% \n  set_engine(\"lm\")\n\nlm_form_fit <- \n  lm_model %>% \n  fit(body_mass_g ~ bill_length_mm + bill_depth_mm, data = penguins_train)\n\nlm_xy_fit <- \n  lm_model %>% \n  fit_xy(\n    x = penguins_train %>% select(bill_length_mm, bill_depth_mm),\n    y = penguins_train %>% pull(body_mass_g)\n  )\n\nlm_form_fit\n## parsnip model object\n## \n## \n## Call:\n## stats::lm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm, \n##     data = data)\n## \n## Coefficients:\n##    (Intercept)  bill_length_mm   bill_depth_mm  \n##        3698.15           69.79         -150.48\n\nlm_xy_fit\n## parsnip model object\n## \n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n##    (Intercept)  bill_length_mm   bill_depth_mm  \n##        3698.15           69.79         -150.48\nlm_form_fit %>% \n  extract_fit_engine()\n## \n## Call:\n## stats::lm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm, \n##     data = data)\n## \n## Coefficients:\n##    (Intercept)  bill_length_mm   bill_depth_mm  \n##        3698.15           69.79         -150.48\n\nlm_form_fit %>% \n  extract_fit_engine() %>% \n  vcov()\n##                (Intercept) bill_length_mm bill_depth_mm\n## (Intercept)     240286.265    -2494.52933   -7522.27997\n## bill_length_mm   -2494.529       45.19213      29.53007\n## bill_depth_mm    -7522.280       29.53007     362.09611\n\nmodel_res <- \n  lm_form_fit %>% \n  extract_fit_engine() %>% \n  summary()\n\nparam_est <- coef(model_res)\n\nclass(param_est)\n## [1] \"matrix\" \"array\"\n\nparam_est\n##                  Estimate Std. Error   t value     Pr(>|t|)\n## (Intercept)    3698.15105 490.190030  7.544321 6.970546e-13\n## bill_length_mm   69.79313   6.722509 10.382006 1.820525e-21\n## bill_depth_mm  -150.47740  19.028823 -7.907867 6.733650e-14\n\nlm_form_fit %>% \n  tidy()\n## # A tibble: 3 x 5\n##   term           estimate std.error statistic  p.value\n##   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)      3698.     490.        7.54 6.97e-13\n## 2 bill_length_mm     69.8      6.72     10.4  1.82e-21\n## 3 bill_depth_mm    -150.      19.0      -7.91 6.73e-14\n\nlm_form_fit %>% \n  glance()\n## # A tibble: 1 x 12\n##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1     0.449         0.445  599.      110. 1.16e-35     2 -2132. 4271. 4286.\n## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\npenguins_test_small <- penguins_test %>%\n  slice(1:5)\n\npredict(lm_form_fit, new_data = penguins_test_small)\n## # A tibble: 5 x 1\n##   .pred\n##   <dbl>\n## 1 3590.\n## 2 3918.\n## 3 3574.\n## 4 3540.\n## 5 3673.\n\npenguins_test_small %>% \n  select(body_mass_g) %>% \n  bind_cols(predict(lm_form_fit, penguins_test_small)) %>% \n  bind_cols(predict(lm_form_fit, penguins_test_small, type = \"pred_int\")) \n## # A tibble: 5 x 4\n##   body_mass_g .pred .pred_lower .pred_upper\n##         <int> <dbl>       <dbl>       <dbl>\n## 1        4250 3590.       2404.       4775.\n## 2        3200 3918.       2737.       5099.\n## 3        3700 3574.       2390.       4758.\n## 4        3450 3540.       2356.       4724.\n## 5        4200 3673.       2481.       4866."},{"path":"tidymodels.html","id":"створення-робочого-процесу-для-побудови-моделей","chapter":" 1 Tidymodels","heading":"1.3 Створення робочого процесу для побудови моделей","text":"","code":"\nlm_model <- \n  linear_reg() %>% \n  set_engine(\"lm\")\n\nlm_wflow <- \n  workflow() %>% \n  add_model(lm_model)\n\nlm_wflow\n## == Workflow ===================================================================\n## Preprocessor: None\n## Model: linear_reg()\n## \n## -- Model ----------------------------------------------------------------------\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nlm_wflow <- \n  lm_wflow %>% \n  add_formula(body_mass_g ~ bill_length_mm + bill_depth_mm)\n\nlm_fit <- fit(lm_wflow, penguins_train)\n\nlm_fit\n## == Workflow [trained] =========================================================\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## body_mass_g ~ bill_length_mm + bill_depth_mm\n## \n## -- Model ----------------------------------------------------------------------\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n##    (Intercept)  bill_length_mm   bill_depth_mm  \n##        3698.15           69.79         -150.48\n\npredict(lm_fit, penguins_train %>% \n          slice(1:3))\n## # A tibble: 3 x 1\n##   .pred\n##   <dbl>\n## 1 3837.\n## 2 3802.\n## 3 3355.\n\nlm_fit %>% \n  update_formula(body_mass_g ~ bill_length_mm)\n## == Workflow ===================================================================\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## body_mass_g ~ bill_length_mm\n## \n## -- Model ----------------------------------------------------------------------\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\nlm_wflow <- \n  lm_wflow %>% \n  remove_formula() %>% \n  add_variables(outcome = body_mass_g, predictors = c(contains(\"_\")))\n\nlm_wflow\n## == Workflow ===================================================================\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## Outcomes: body_mass_g\n## Predictors: c(contains(\"_\"))\n## \n## -- Model ----------------------------------------------------------------------\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nfit(lm_wflow, penguins_train)\n## == Workflow [trained] =========================================================\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## Outcomes: body_mass_g\n## Predictors: c(contains(\"_\"))\n## \n## -- Model ----------------------------------------------------------------------\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n##       (Intercept)     bill_length_mm      bill_depth_mm  flipper_length_mm  \n##         -6656.034              2.846             21.343             51.511\nformulas <- list(\n  bill_length = body_mass_g ~ bill_length_mm,\n  bill_depth = body_mass_g ~ bill_depth_mm,\n  bill_length_depth = body_mass_g ~ bill_length_mm + bill_depth_mm + sex,\n  flipper = body_mass_g ~ flipper_length_mm\n)\n\nlibrary(workflowsets)\n\nformulas_model <- workflow_set(preproc = formulas, models = list(lm = lm_model))\n\nformulas_model\n## # A workflow set/tibble: 4 x 4\n##   wflow_id             info             option    result    \n##   <chr>                <list>           <list>    <list>    \n## 1 bill_length_lm       <tibble [1 x 4]> <opts[0]> <list [0]>\n## 2 bill_depth_lm        <tibble [1 x 4]> <opts[0]> <list [0]>\n## 3 bill_length_depth_lm <tibble [1 x 4]> <opts[0]> <list [0]>\n## 4 flipper_lm           <tibble [1 x 4]> <opts[0]> <list [0]>\n\nformulas_model$info[[1]]\n## # A tibble: 1 x 4\n##   workflow   preproc model      comment\n##   <list>     <chr>   <chr>      <chr>  \n## 1 <workflow> formula linear_reg \"\"\n\nextract_workflow(formulas_model, id = \"flipper_lm\")\n## == Workflow ===================================================================\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## body_mass_g ~ flipper_length_mm\n## \n## -- Model ----------------------------------------------------------------------\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nformulas_model <-\n   formulas_model %>%\n   mutate(fit = map(info, ~ fit(.x$workflow[[1]], penguins_train)))\n\nformulas_model\n## # A workflow set/tibble: 4 x 5\n##   wflow_id             info             option    result     fit       \n##   <chr>                <list>           <list>    <list>     <list>    \n## 1 bill_length_lm       <tibble [1 x 4]> <opts[0]> <list [0]> <workflow>\n## 2 bill_depth_lm        <tibble [1 x 4]> <opts[0]> <list [0]> <workflow>\n## 3 bill_length_depth_lm <tibble [1 x 4]> <opts[0]> <list [0]> <workflow>\n## 4 flipper_lm           <tibble [1 x 4]> <opts[0]> <list [0]> <workflow>\n\nformulas_model$fit[[1]]\n## == Workflow [trained] =========================================================\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## body_mass_g ~ bill_length_mm\n## \n## -- Model ----------------------------------------------------------------------\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n##    (Intercept)  bill_length_mm  \n##         572.09           82.07"},{"path":"tidymodels.html","id":"фіча-інженірінг","chapter":" 1 Tidymodels","heading":"1.4 Фіча інженірінг","text":"","code":"\n\npenguins_train\n## # A tibble: 275 x 8\n##    body_mass_g species island    bill_length_mm bill_depth_mm flipper_length_mm\n##          <int> <fct>   <fct>              <dbl>         <dbl>             <int>\n##  1        3800 Adelie  Torgersen           39.5          17.4               186\n##  2        3250 Adelie  Torgersen           40.3          18                 195\n##  3        3450 Adelie  Torgersen           36.7          19.3               193\n##  4        3625 Adelie  Torgersen           38.9          17.8               181\n##  5        3475 Adelie  Torgersen           34.1          18.1               193\n##  6        3300 Adelie  Torgersen           37.8          17.1               186\n##  7        3700 Adelie  Torgersen           37.8          17.3               180\n##  8        3325 Adelie  Torgersen           34.4          18.4               184\n##  9        3400 Adelie  Biscoe              37.8          18.3               174\n## 10        3800 Adelie  Biscoe              35.9          19.2               189\n## # ... with 265 more rows, and 2 more variables: sex <fct>, year <int>\n\nsimple_penguins <- \n  recipe(body_mass_g ~ bill_length_mm + bill_depth_mm + sex,\n         data = penguins_train) %>%\n  step_log(bill_depth_mm, base = 10) %>% \n  step_dummy(all_nominal_predictors())\n\nsimple_penguins\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          3\n## \n## Operations:\n## \n## Log transformation on bill_depth_mm\n## Dummy variables from all_nominal_predictors()\n# lm_wflow %>% \n# add_recipe(simple_penguins)\n\nlm_wflow <- \n  lm_wflow %>% \n  remove_variables() %>% \n  add_recipe(simple_penguins)\n\nlm_wflow\n## == Workflow ===================================================================\n## Preprocessor: Recipe\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## 2 Recipe Steps\n## \n## * step_log()\n## * step_dummy()\n## \n## -- Model ----------------------------------------------------------------------\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nlm_fit <- fit(lm_wflow, penguins_train)\n\npredict(lm_fit, penguins_train %>% slice(1:3))\n## # A tibble: 3 x 1\n##   .pred\n##   <dbl>\n## 1 3479.\n## 2 3351.\n## 3 2923.\n\nlm_fit %>% \n  tidy()\n## # A tibble: 4 x 5\n##   term           estimate std.error statistic  p.value\n##   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)     15141.     897.       16.9  9.06e-44\n## 2 bill_length_mm     31.3      5.73      5.46 1.10e- 7\n## 3 bill_depth_mm  -10396.     636.      -16.3  7.54e-42\n## 4 sex_male          958.      66.3      14.5  3.16e-35\npenguins_train %>% \n  ggplot(aes(sex)) +\n  geom_bar()\n\nsimple_penguins <- \n  recipe(body_mass_g ~ bill_length_mm + bill_depth_mm + sex,\n         data = penguins_train) %>%\n  step_log(bill_depth_mm, base = 10) %>% \n  step_dummy(all_nominal_predictors()) %>% # one_hot = TRUE\n  step_unknown(sex, new_level = \"unknown sex\")\n\n# step_novel()\n# step_other(var_name, threshold = 0.01)\n\nsimple_penguins\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          3\n## \n## Operations:\n## \n## Log transformation on bill_depth_mm\n## Dummy variables from all_nominal_predictors()\n## Unknown factor level assignment for sex\nggplot(penguins_train, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point() + \n  facet_wrap(~ species) + \n  geom_smooth(method = lm, formula = y ~ x, se = FALSE, color = \"lightblue\") + \n  scale_x_log10() + \n  scale_y_log10() + \n  labs(x = \"Довжина плавника\", y = \"Вага\")\n\n# body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + sex + flipper_length_mm:sex\n\n# body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm*sex\n\nsimple_penguins <- \n  recipe(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + sex,\n         data = penguins_train) %>%\n  step_log(bill_depth_mm, base = 10) %>% \n  step_dummy(all_nominal_predictors()) %>% # one_hot = TRUE\n  step_unknown(sex, new_level = \"unknown sex\") %>% \n  step_interact( ~ flipper_length_mm:sex)\nlibrary(patchwork)\nlibrary(splines)\n\nplot_smoother <- function(deg_free) {\n  ggplot(penguins_train, aes(x = bill_depth_mm, y = body_mass_g)) + \n    geom_point(alpha = .2) + \n    scale_y_log10() +\n    geom_smooth(\n      method = lm,\n      formula = y ~ ns(x, df = deg_free),\n      color = \"lightblue\",\n      se = FALSE\n    ) +\n    labs(title = paste(deg_free, \"Spline Terms\"),\n         y = \"Вага\")\n}\n\n( plot_smoother(2) + plot_smoother(5) ) / ( plot_smoother(20) + plot_smoother(30) )\n\nsimple_penguins <- \n  recipe(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + sex,\n         data = penguins_train) %>%\n  step_log(bill_depth_mm, base = 10) %>% \n  step_dummy(all_nominal_predictors()) %>% # one_hot = TRUE\n  step_unknown(sex, new_level = \"unknown sex\") %>% \n  step_interact( ~ flipper_length_mm:sex) %>% \n  step_ns(bill_depth_mm, deg_free = 5)\ntidy(simple_penguins)\n## # A tibble: 5 x 6\n##   number operation type     trained skip  id            \n##    <int> <chr>     <chr>    <lgl>   <lgl> <chr>         \n## 1      1 step      log      FALSE   FALSE log_drhW1     \n## 2      2 step      dummy    FALSE   FALSE dummy_rDO3E   \n## 3      3 step      unknown  FALSE   FALSE unknown_Itj5p \n## 4      4 step      interact FALSE   FALSE interact_RfO0k\n## 5      5 step      ns       FALSE   FALSE ns_6YYfP\n\nsimple_penguins <- \n  recipe(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + sex,\n         data = penguins_train) %>%\n  step_log(bill_depth_mm, base = 10) %>% \n  step_unknown(sex, new_level = \"unknown sex\", id = \"my_id\") # add id\n#  step_dummy(all_nominal_predictors()) %>% # one_hot = TRUE\n#  step_interact( ~ flipper_length_mm:sex) %>% \n#  step_ns(bill_depth_mm, deg_free = 2)\n\ntidy(simple_penguins)\n## # A tibble: 2 x 6\n##   number operation type    trained skip  id       \n##    <int> <chr>     <chr>   <lgl>   <lgl> <chr>    \n## 1      1 step      log     FALSE   FALSE log_M3wCq\n## 2      2 step      unknown FALSE   FALSE my_id\n\nlm_wflow <- \n  workflow() %>% \n  add_model(lm_model) %>% \n  add_recipe(simple_penguins)\n\nlm_fit <- fit(lm_wflow, penguins_train)\n\nestimated_recipe <- lm_fit %>% \n  extract_recipe(estimated = TRUE)\npenguins_test_res <- predict(lm_fit, new_data = penguins_train %>%\n                               select(-body_mass_g))\n\npenguins_test_res\n\n\npenguins_test_res <- bind_cols(penguins_test_res, penguins_train %>%\n                                 select(body_mass_g))\n\npenguins_test_res\n\nggplot(penguins_test_res, aes(x = body_mass_g, y = .pred)) + \n  # Create a diagonal line:\n  geom_abline(lty = 2) + \n  geom_point(alpha = 0.5) + \n  labs(y = \"Predicted Body Mass\", x = \"Body Mass\") +\n  # Scale and size the x- and y-axis uniformly:\n  coord_obs_pred()\n\nrmse(penguins_test_res, truth = body_mass_g, estimate = .pred)\n\npenguins_metrics <- metric_set(rmse, rsq, mae)\npenguins_metrics(penguins_test_res, truth = body_mass_g, estimate = .pred)"},{"path":"reg.html","id":"reg","chapter":" 2 Лінійна регресія","heading":" 2 Лінійна регресія","text":"Модель лінійної регресії:\n\\[\\hat{y} = \\beta_0 + \\sum \\beta_j x_j\\]\n\\(\\beta_0\\) - вільний коефіцієнт (bias, intercept)\\(\\beta_j\\) - ваговий коефіцієнт (weights)\\(\\beta_0, \\beta_1, \\dots, \\beta_n\\) - параметриІнколи можуть скорочувати запис формули:\n\\[\\hat{y} = \\beta_0 + \\left \\langle \\beta, x \\right \\rangle\\]$$$$","code":""},{"path":"reg.html","id":"коли-такі-моделі-можна-використовувати","chapter":" 2 Лінійна регресія","heading":"2.1 Коли такі моделі можна використовувати?","text":"","code":""},{"path":"reg.html","id":"номінативні-показники-one-hot-encoding","chapter":" 2 Лінійна регресія","heading":"2.1.1 Номінативні показники: one-hot encoding","text":"Припустимо, що один з наших показників \\(x_j\\) номінативний і він приймає значення з певної множини значень \\(x_j \\\\left \\{ c_1, c_2, \\dots, c_m \\right \\}\\)Основна мета one-hot encoding створити нові бінарні змінні з якими модель регресії зможе працювати:\\(b_i(x) = \\left [ f_i(x) = c_i \\right ]\\)Нотація Айверсона:\n\\[\\left [ \\models  \\right ] = 1\\]\n\\[\\left [ ⊭  \\right ] = 0\\]\\(b_1(x), b_2(x), \\dots, b_m(x)\\) - нові показники.Як в такому випадку буде виглядати модель?\\[\\hat{y} = \\beta_0 + \\beta_1\\left [ b(x) = c_1 \\right ] + \\dots + \\beta_m\\left [ b(x) = c_m \\right ] + \\dots\\]","code":""},{"path":"reg.html","id":"бінаризація","chapter":" 2 Лінійна регресія","heading":"2.1.2 Бінаризація","text":"В випадках, коли в нас існує нелінійна залежність між \\(y\\) та \\(x\\) є сенс використати бінеризацію.\nБудуємо певну сітку значень \\({t_1, t_2, \\dots, t_m}\\), тоді нові показники задамо як:\\[b_i(x) = [t_{-1} < x_j \\leqslant t_{}], \\;\\; = 1,\\dots,m+1\\]\nЛінійна модель набуває вигляду:\n\\[\\hat{y} = \\beta_1\\left [ t_{-1} < x_j \\leqslant t_{} \\right ] + \\dots + \\beta_m\\left [ t_{m} < x_j \\leqslant t_{m+1} \\right ] + \\dots\\]\nМежі інтервалів можна подавати, як перцентилі.","code":""},{"path":"reg.html","id":"текстові-дані-bag-of-words","chapter":" 2 Лінійна регресія","heading":"2.1.3 Текстові дані: bag of words","text":"","code":""},{"path":"reg.html","id":"похибки-в-задачах-регресії","chapter":" 2 Лінійна регресія","heading":"2.2 Похибки в задачах регресії","text":"\\[L(y, \\hat{y})\\]\n### Квадратична функція похибок\n\\[L(y, \\hat{y}) = (y - \\hat{y})^2\\]\\[MSE(\\hat{y}, x) = \\frac{1}{l}\\sum(y - \\hat{y}(x))^2\\]\\[RMSE(\\hat{y}, x) = \\sqrt{\\frac{1}{l}\\sum(y - \\hat{y}(x))^2}\\]\n\\[R^2(\\hat{y}, x) = 1 - \\frac{\\sum(y - \\hat{y})^2}{\\sum(y - \\overline{y})^2}\\]","code":""},{"path":"reg.html","id":"абсолютна-функція-похибок","chapter":" 2 Лінійна регресія","heading":"2.2.1 Абсолютна функція похибок","text":"\\[L(y, \\hat{y}) = |y - \\hat{y}|\\]\\[MAE(\\hat{y}, x) = \\frac{1}{l}\\sum|y - \\hat{y}|\\]\nПозитивні сторони: стійка до викидівНегативні сторони: похідна не має інформації про близькість екстремуму + не має похідної в нулі.","code":""},{"path":"reg.html","id":"huber-loss","chapter":" 2 Лінійна регресія","heading":"2.2.2 Huber loss","text":"Поєднання квадратичної та абсолютної функції. Необхідно підбирати дельту. Не має другої похідної.\n\\[\nL_{\\delta}(y, \\hat{y})\\left\\{\\begin{matrix}\n\\frac{1}{2}(y - \\hat{y})^2, & |y - \\hat{y}| <  \\delta \\\\ \n\\delta (|y - \\hat{y}| - \\frac{1}{2}\\delta) & |y - \\hat{y}| \\geqslant   \\delta   \n\\end{matrix}\\right.\n\\]","code":""},{"path":"reg.html","id":"log-cosh","chapter":" 2 Лінійна регресія","heading":"2.2.3 Log-Cosh","text":"Використовується гіперболічний косинус\n\\[\nL_{\\delta}(y, \\hat{y}) = log (cosh(y - \\hat{y}))\n\\]","code":""},{"path":"reg.html","id":"msle","chapter":" 2 Лінійна регресія","heading":"2.2.4 MSLE","text":"Mean squared logarithmic error\n\\[\nL(y, \\hat{y}) = (log(\\hat{y} + 1) - log(y + 1))^2\n\\]","code":""},{"path":"reg.html","id":"відносні-функції-помилок","chapter":" 2 Лінійна регресія","heading":"2.2.5 Відносні функції помилок","text":"","code":""},{"path":"reg.html","id":"mape","chapter":" 2 Лінійна регресія","heading":"2.2.5.1 MAPE","text":"\\[\nL_{\\delta}(y, \\hat{y}) = |\\frac{y - \\hat{y}}{y}|\n\\]","code":""},{"path":"reg.html","id":"smape","chapter":" 2 Лінійна регресія","heading":"2.2.5.2 SMAPE","text":"\\[\nL_{\\delta}(y, \\hat{y}) = \\frac{|y - \\hat{y}|}{(|y| + |\\hat{y}|)/2}\n\\]","code":""},{"path":"reg.html","id":"квантильна-функції","chapter":" 2 Лінійна регресія","heading":"2.2.6 Квантильна функції","text":"Можна регулювати штраф за завищення і заниження похибокФункцію помилок потрібно підбирати в залежності від задачі.","code":""},{"path":"reg.html","id":"перенавчання","chapter":" 2 Лінійна регресія","heading":"2.3 Перенавчання","text":"Нерідко в моделі машинного навчання стикаються з ситуацією перенавчання — якість моделі на нових даних значно гірша ніж на навчальній вибірці. Тому важливо щоб наша модель вміла узагалювати свої результати на нові дані.Для візуалізації цього ефекту проведемо симуляцію:Візуалізація демострує, що прості моделі мають недостатню точність, а складні моделі занадто добре підлаштовуються під вибірку, через що стають непридатними для подальшого використання.Існує декілька варіантів виходу з ситуації перенавчання:регуляризація: штрафування моделі за складністьрегуляризація: штрафування моделі за складністькрос-валідація: побудова низки моделей на підвибірках данихкрос-валідація: побудова низки моделей на підвибірках данихзбільшення розмірності вибірки (про цей варіант часто забувають).збільшення розмірності вибірки (про цей варіант часто забувають).","code":"\nlibrary(tidyverse)\nlibrary(patchwork)\n\nset.seed(1234)\n\ndf <- tibble(x = seq(1, 2, 0.05),\n             y = cos(1.5 * pi * x) + rnorm(x, 0, 0.1))\n\nplots <- map(c(1, 4, 15), function(d){\n  ggplot(df, aes(x, y)) +\n    geom_point() + \n    # geom_smooth(se = FALSE, color = \"#2F6B57\") + \n    geom_smooth(method = \"lm\", formula = y ~ poly(x, d), se = FALSE, color = \"#2F6B57\") +\n    ggtitle(paste(\"Poly \", d))\n})\n\nplots[[1]] / plots[[2]] / plots[[3]]"},{"path":"reg.html","id":"оцінювання-якості-моделей","chapter":" 2 Лінійна регресія","heading":"2.4 Оцінювання якості моделей","text":"Адекватна оцінка якості моделі грунтується на підході відкладеної вибірки: розмічені дані (дані, з відомими відповідями) розбиваються на дві частини: навчальну та тестову. На навчальній вибірці модель навчається а на тестовій перевіряється її якість. Якщо показник якості моделі на тестовій вибірці задовольняє наші потреби, можемо вважати, що модель знайшла певні закономірності в даних.Але бувають випадки, коли якість моделі залежить від “формату” розбиття на підвибірки: ми можемо отримати різну якість моделі, якщо розіб’ємо дані за інших пропорцій або іншого початкового значення генератора випадкових величин. Вирішити таку проблему можна за допомогою крос-валідації. Дані розбиваються на \\(k\\) блоків \\(X_1, X_2,\\dots,X_k\\) приблизно однакового розміру. Після чого будується \\(k\\) моделей \\(\\hat{y_1},\\dots,\\hat{y_k}\\), при чому кожна \\(k\\) модель навчається на всіх блоках окрім \\(k\\). Після чого кожна модель оцінюється оцінюється по блоку який не приймав в навчанні, а результати усереднюються:\\[CV = \\frac{1}{k}\\sum{Q(\\hat{y_i}, X_i)}\\]Як отримати фінальну модель для подальшого використання? Два варіанта:Навчаємо модель на всій вибірці даних, її параметри будуть підібрані на більшій кількості спостережень і можемо сподіватися, що якість моделі зросте.Навчаємо модель на всій вибірці даних, її параметри будуть підібрані на більшій кількості спостережень і можемо сподіватися, що якість моделі зросте.Будуємо композицію моделі з \\(\\hat{y_1},\\dots,\\hat{y_k}\\): наприклад, усереднення прогнозів всіх моделей, що може привести до підвищення стійкості моделі.Будуємо композицію моделі з \\(\\hat{y_1},\\dots,\\hat{y_k}\\): наприклад, усереднення прогнозів всіх моделей, що може привести до підвищення стійкості моделі.","code":"\nlibrary(tidymodels)\n\nset.seed(1234)\nn <- 1e3\n\nll_df <- tibble(\n  x = runif(n, 0, 3),\n  y = exp(1 + 0.75 * x + rnorm(n, sd = 0.5))\n)\n\nsplit <- initial_split(ll_df, prop = 0.8)\nsplit\n## <Analysis/Assess/Total>\n## <800/200/1000>\n\ncars_train <- training(split)\ncars_test <- testing(split)\n\ncars_train\n## # A tibble: 800 x 2\n##        x     y\n##    <dbl> <dbl>\n##  1 2.62  17.5 \n##  2 1.47   8.59\n##  3 0.717  2.52\n##  4 2.75  26.3 \n##  5 0.931  2.74\n##  6 1.68  10.6 \n##  7 0.384  2.59\n##  8 1.20   4.09\n##  9 0.555  3.29\n## 10 1.99  11.0 \n## # ... with 790 more rows\ncars_test\n## # A tibble: 200 x 2\n##        x     y\n##    <dbl> <dbl>\n##  1 1.87  10.5 \n##  2 1.92  10.2 \n##  3 2.08   7.63\n##  4 2.77  36.5 \n##  5 2.51  11.6 \n##  6 0.560  5.12\n##  7 0.697  8.82\n##  8 0.120  2.98\n##  9 0.656  3.17\n## 10 0.935  3.96\n## # ... with 190 more rows\nlm_spec <- linear_reg() %>%\n  set_mode(\"regression\") %>%\n  set_engine(\"lm\")\n\nlm_fit <- lm_spec %>% \n  fit(y ~ x, data = cars_train)\n\naugment(lm_fit, new_data = cars_train) %>%\n  yardstick::rmse(truth = y, estimate = .pred)\n## # A tibble: 1 x 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rmse    standard        6.93\n\naugment(lm_fit, new_data = cars_test) %>%\n  yardstick::rmse(truth = y, estimate = .pred)\n## # A tibble: 1 x 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rmse    standard        7.68\n\npredict(lm_fit, new_data = cars_test)\n## # A tibble: 200 x 1\n##     .pred\n##     <dbl>\n##  1 14.2  \n##  2 14.6  \n##  3 15.9  \n##  4 21.3  \n##  5 19.3  \n##  6  3.88 \n##  7  4.95 \n##  8  0.406\n##  9  4.63 \n## 10  6.83 \n## # ... with 190 more rows\n\npredict(lm_fit, new_data = cars_test, type = \"conf_int\")\n## # A tibble: 200 x 2\n##    .pred_lower .pred_upper\n##          <dbl>       <dbl>\n##  1      13.7         14.7 \n##  2      14.1         15.1 \n##  3      15.3         16.4 \n##  4      20.5         22.1 \n##  5      18.5         20.0 \n##  6       3.15         4.60\n##  7       4.29         5.62\n##  8      -0.512        1.32\n##  9       3.95         5.32\n## 10       6.25         7.42\n## # ... with 190 more rows\n\nbind_cols(\n  predict(lm_fit, new_data = ll_df),\n  ll_df\n) %>%\n  select(y, .pred)\n## # A tibble: 1,000 x 2\n##        y  .pred\n##    <dbl>  <dbl>\n##  1  5.74  2.15 \n##  2  5.98 14.2  \n##  3 15.3  13.9  \n##  4 10.5  14.2  \n##  5 46.0  19.8  \n##  6 10.2  14.6  \n##  7  1.29 -0.316\n##  8  5.87  4.96 \n##  9 14.5  15.2  \n## 10  8.57 11.6  \n## # ... with 990 more rows\npoly_tuned_rec <- recipe(y ~ x, data = cars_train) %>%\n  step_poly(x, degree = tune())\n\npoly_tuned_wf <- workflow() %>%\n  add_recipe(poly_tuned_rec) %>%\n  add_model(lm_spec)\n\ncars_folds <- vfold_cv(cars_train, v = 10)\n\ndegree_grid <- grid_regular(degree(range = c(1, 10)), levels = 10)\ndegree_grid <- tibble(degree = seq(1, 10)) # same\n\ntune_res <- tune_grid(\n  object = poly_tuned_wf, \n  resamples = cars_folds, \n  grid = degree_grid\n)\n\nautoplot(tune_res)\n\ncollect_metrics(tune_res)\n## # A tibble: 20 x 7\n##    degree .metric .estimator  mean     n std_err .config              \n##     <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n##  1      1 rmse    standard   6.88     10  0.319  Preprocessor01_Model1\n##  2      1 rsq     standard   0.504    10  0.0197 Preprocessor01_Model1\n##  3      2 rmse    standard   6.66     10  0.271  Preprocessor02_Model1\n##  4      2 rsq     standard   0.540    10  0.0174 Preprocessor02_Model1\n##  5      3 rmse    standard   6.67     10  0.269  Preprocessor03_Model1\n##  6      3 rsq     standard   0.538    10  0.0172 Preprocessor03_Model1\n##  7      4 rmse    standard   6.67     10  0.267  Preprocessor04_Model1\n##  8      4 rsq     standard   0.537    10  0.0168 Preprocessor04_Model1\n##  9      5 rmse    standard   6.68     10  0.263  Preprocessor05_Model1\n## 10      5 rsq     standard   0.536    10  0.0168 Preprocessor05_Model1\n## 11      6 rmse    standard   6.68     10  0.260  Preprocessor06_Model1\n## 12      6 rsq     standard   0.537    10  0.0169 Preprocessor06_Model1\n## 13      7 rmse    standard   6.68     10  0.259  Preprocessor07_Model1\n## 14      7 rsq     standard   0.538    10  0.0164 Preprocessor07_Model1\n## 15      8 rmse    standard   6.69     10  0.260  Preprocessor08_Model1\n## 16      8 rsq     standard   0.537    10  0.0166 Preprocessor08_Model1\n## 17      9 rmse    standard   6.69     10  0.261  Preprocessor09_Model1\n## 18      9 rsq     standard   0.535    10  0.0165 Preprocessor09_Model1\n## 19     10 rmse    standard   6.71     10  0.262  Preprocessor10_Model1\n## 20     10 rsq     standard   0.533    10  0.0164 Preprocessor10_Model1\n\nshow_best(tune_res, metric = \"rmse\", n = 1)\n## # A tibble: 1 x 7\n##   degree .metric .estimator  mean     n std_err .config              \n##    <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n## 1      2 rmse    standard    6.66    10   0.271 Preprocessor02_Model1\n\nbest_degree <- show_best(tune_res, metric = \"rmse\", n = 1)\n\nfinal_wf <- finalize_workflow(poly_tuned_wf, best_degree)\n\nfinal_wf\n## == Workflow ===================================================================\n## Preprocessor: Recipe\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## 1 Recipe Step\n## \n## * step_poly()\n## \n## -- Model ----------------------------------------------------------------------\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nfinal_fit <- fit(final_wf, cars_train)\n\nfinal_fit\n## == Workflow [trained] =========================================================\n## Preprocessor: Recipe\n## Model: linear_reg()\n## \n## -- Preprocessor ---------------------------------------------------------------\n## 1 Recipe Step\n## \n## * step_poly()\n## \n## -- Model ----------------------------------------------------------------------\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)     x_poly_1     x_poly_2  \n##       11.52       193.74        52.76\n\nbind_cols(\n  predict(final_fit, new_data = ll_df),\n  ll_df\n) %>%\n  select(y, .pred)\n## # A tibble: 1,000 x 2\n##        y .pred\n##    <dbl> <dbl>\n##  1  5.74  3.91\n##  2  5.98 12.5 \n##  3 15.3  12.1 \n##  4 10.5  12.5 \n##  5 46.0  20.8 \n##  6 10.2  13.0 \n##  7  1.29  3.71\n##  8  5.87  4.78\n##  9 14.5  13.8 \n## 10  8.57  9.58\n## # ... with 990 more rows\n\naugment(final_fit, new_data = cars_train) %>%\n  yardstick::rmse(truth = y, estimate = .pred)\n## # A tibble: 1 x 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rmse    standard        6.68\n\naugment(final_fit, new_data = cars_test) %>%\n  yardstick::rmse(truth = y, estimate = .pred)\n## # A tibble: 1 x 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rmse    standard        7.46"},{"path":"reg.html","id":"градієнтний-спуск","chapter":" 2 Лінійна регресія","heading":"2.5 Градієнтний спуск","text":"Пізніше…","code":""},{"path":"reg.html","id":"приклад-використання","chapter":" 2 Лінійна регресія","heading":"2.6 Приклад використання","text":"bookdown::render_book(“index.Rmd,” output_dir = “docs”)","code":"\nfm0 <- lm(y ~ x, ll_df)\nX <- model.matrix(fm0)\nf1 <- function(b) with(ll_df, sum(log(cosh(y - X %*% b))))\nres <- optim(coef(fm0), f1, method = \"BFGS\")\nres$par\n## (Intercept)           x \n##    1.105912    5.920392\n\nf2 <- function(b) with(ll_df, mean(abs((y - X %*% b))))\nres <- optim(coef(fm0), f2, method = \"BFGS\")\nres$par\n## (Intercept)           x \n##    1.262496    5.800633\nf1 <- function(b) with(ll_df, sum(log(cosh(y - X %*% b))))\nf2 <- function(b) with(ll_df, mean(abs((y - X %*% b))))\nfunc <- list(f1, f2)\nfm0 <- lm(y ~ x, ll_df)\nX <- model.matrix(fm0)\nparam <- 0\n\nfor (i in 1:length(func)) {\n  param[i] <- tibble(optim(coef(fm0), func[[i]], method = \"BFGS\")$par)\n}\n\nparam <- param %>% \n  bind_rows(lm_fit$fit$coefficients) %>% \n  rename(Intercept = 1) %>% \n  mutate(loss = c(\"Log-Cosh\", \"MAE\", \"MSE\"))\n\nll_df %>% \n  ggplot(aes(x, y)) +\n  geom_point(alpha = .2) +\n  geom_abline(data = param, aes(intercept = Intercept, slope = x, color = loss), size = 1)"},{"path":"classification.html","id":"classification","chapter":" 3 Класифікація","heading":" 3 Класифікація","text":"","code":""},{"path":"references.html","id":"references","chapter":"Література","heading":"Література","text":"text","code":""}]
